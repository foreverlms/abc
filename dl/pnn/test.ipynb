{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d5e85c4-5083-4819-bd75-b247b83ab27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "from onnx.helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16107332-e598-4f34-b905-e70ac7b514a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a2a9052-278c-47c6-a76e-f63fefb427aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = make_tensor_value_info('data', TensorProto.FLOAT, [1, 3, 16, 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94106201-b683-4706-a5ab-866d1d951fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = make_tensor_value_info('output', TensorProto.FLOAT, [1, 3,8,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be40fed2-1b45-4534-8b93-f938a9e65128",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_def = make_node(\n",
    "    'Resize',                  # name\n",
    "    ['data',], # inputs\n",
    "    ['Y'],                  # outputs\n",
    "    mode='linear'        # attributes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2acc0fe6-285e-4ff2-b022-8dd849700b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_def = make_graph(\n",
    "    [node_def],        # nodes\n",
    "    'test-resize',      # name\n",
    "    [X],  # inputs\n",
    "    [Y],               # outputs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ead5968-9b58-4adb-9c9b-9dd0cad8da29",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_def = make_model(graph_def, producer_name='onnx-example')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bda80359-df3f-4dff-8e2c-9d0a2c72cb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx.checker.check_model(model_def)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f3d97ad-1254-4c43-8cc7-4ffa236f6055",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Input 2 is out of bounds.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m inferred_model \u001b[38;5;241m=\u001b[39m \u001b[43monnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape_inference\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer_shapes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_def\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/d2l/lib/python3.8/site-packages/onnx/shape_inference.py:42\u001b[0m, in \u001b[0;36minfer_shapes\u001b[0;34m(model, check_type, strict_mode, data_prop)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, (ModelProto, binary_type)):\n\u001b[1;32m     41\u001b[0m     model_str \u001b[38;5;241m=\u001b[39m model \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, binary_type) \u001b[38;5;28;01melse\u001b[39;00m model\u001b[38;5;241m.\u001b[39mSerializeToString()\n\u001b[0;32m---> 42\u001b[0m     inferred_model_str \u001b[38;5;241m=\u001b[39m \u001b[43mC\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer_shapes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_prop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m onnx\u001b[38;5;241m.\u001b[39mload_from_string(inferred_model_str)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, string_types):\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Input 2 is out of bounds."
     ]
    }
   ],
   "source": [
    "inferred_model = onnx.shape_inference.infer_shapes(model_def)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "47d2af61-2ffb-40cb-94a7-ec5128b81044",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "38477a7a-a74c-46c9-9c81-2f2aef394a18",
   "metadata": {},
   "outputs": [],
   "source": [
    " m = nn.Upsample(scale_factor=(0.5,0.5), mode='bilinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ea0cf11c-f2d3-4131-b361-5d5d874ae6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.randn(1, 3, 16, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ad4a8da2-fe9b-447e-8761-a1f8ba6ad29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/d2l/lib/python3.8/site-packages/torch/nn/functional.py:3679: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "output = m(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dd796ba0-8bee-43a3-8849-df5474eca87b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 8, 8])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c12e733e-084b-42cc-9b5d-bea7e4026672",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateDataList(data, count, begin ,truncateBase):\n",
    "    for i in range(count):\n",
    "        res = (i + begin) if ((i + begin) < 0) else ((i + begin) % truncateBase)\n",
    "        data.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c5f43731-04c6-40ac-8ff3-0cb415a63043",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/d2l/lib/python3.8/site-packages/torch/nn/functional.py:3631: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/d2l/lib/python3.8/site-packages/torch/nn/functional.py:3679: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/d2l/lib/python3.8/site-packages/torch/onnx/symbolic_helper.py:381: UserWarning: You are trying to export the model with onnx:Resize for ONNX opset version 10. This operator might cause results to not match the expected results by PyTorch.\n",
      "ONNX's Upsample/Resize operator did not match Pytorch's Interpolation until opset 11. Attributes to determine how to transform the input were added in onnx:Resize in opset 11 to support Pytorch's behavior (like coordinate_transformation_mode and nearest_mode).\n",
      "We recommend using opset 11 and above for models using this operator.\n",
      "  warnings.warn(\"You are trying to export the model with \" + onnx_op + \" for ONNX opset version \"\n"
     ]
    }
   ],
   "source": [
    "torch.onnx.export(m,               # model being run\n",
    "                  data,                         # model input (or a tuple for multiple inputs)\n",
    "                  \"/Users/bob/docs/ByteDance/PNN/converter/quality/upsample.onnx\",   # where to save the model (can be a file or file-like object)\n",
    "                  export_params=True,        # store the trained parameter weights inside the model file\n",
    "                  opset_version=10,          # the ONNX version to export the model to\n",
    "                  do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                  input_names = ['data'],   # the model's input names\n",
    "                  output_names = ['output'], # the model's output names\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a5a6d77b-2eca-44df-83b0-0dcaef070cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/Users/bob/docs/ByteDance/PNN/converter/quality/upsample.onnx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2169770c-9e54-4cb2-8e7a-991e14f2f0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8e3679f1-a174-4fdb-b5f2-9e9056bbddce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = ort.InferenceSession(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "12cabcb5-af13-4430-a8cf-a7857b6cb6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "begin = 1\n",
    "truncateBase = 13\n",
    "upsample_data = []\n",
    "CreateDataList(upsample_data, 1*3*16*16, begin, truncateBase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f4502b-c1ac-4a51-b5ad-9495e4b95f7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c912495f-f8ee-4cb3-b234-a71fdbef25f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "upsample_data = np.array(upsample_data,dtype=np.float32).reshape([1,3,16,16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "344da32f-ee30-4e4b-9283-8cf6d93f2b65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 16, 16)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upsample_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ed35a08a-1e87-4063-a7cc-2def27907ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs  = sess.run(None, {\"data\" : upsample_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1e120d53-82f3-4af5-8bdb-956eae02a07d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  3.,  5.,  7.,  9., 11.,  0.,  2.,  7.,  9., 11.,  0.,  2.,\n",
       "        4.,  6.,  8.,  0.,  2.,  4.,  6.,  8., 10., 12.,  1.,  6.,  8.,\n",
       "       10., 12.,  1.,  3.,  5.,  7., 12.,  1.,  3.,  5.,  7.,  9., 11.,\n",
       "        0.,  5.,  7.,  9., 11.,  0.,  2.,  4.,  6., 11.,  0.,  2.,  4.,\n",
       "        6.,  8., 10., 12.,  4.,  6.,  8., 10., 12.,  1.,  3.,  5., 10.,\n",
       "       12.,  1.,  3.,  5.,  7.,  9., 11.,  3.,  5.,  7.,  9., 11.,  0.,\n",
       "        2.,  4.,  9., 11.,  0.,  2.,  4.,  6.,  8., 10.,  2.,  4.,  6.,\n",
       "        8., 10., 12.,  1.,  3.,  8., 10., 12.,  1.,  3.,  5.,  7.,  9.,\n",
       "        1.,  3.,  5.,  7.,  9., 11.,  0.,  2.,  7.,  9., 11.,  0.,  2.,\n",
       "        4.,  6.,  8.,  0.,  2.,  4.,  6.,  8., 10., 12.,  1.,  6.,  8.,\n",
       "       10., 12.,  1.,  3.,  5.,  7., 12.,  1.,  3.,  5.,  7.,  9., 11.,\n",
       "        0.,  5.,  7.,  9., 11.,  0.,  2.,  4.,  6., 11.,  0.,  2.,  4.,\n",
       "        6.,  8., 10., 12.,  4.,  6.,  8., 10., 12.,  1.,  3.,  5., 10.,\n",
       "       12.,  1.,  3.,  5.,  7.,  9., 11.,  3.,  5.,  7.,  9., 11.,  0.,\n",
       "        2.,  4.,  9., 11.,  0.,  2.,  4.,  6.,  8., 10.], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0].flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cf5ec5-4fc4-41c5-8882-c5183a80dc7a",
   "metadata": {},
   "source": [
    "### Winograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "871843f7-efd0-46ab-8c49-0cfad0275a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import Symbol, symbols, Matrix, Poly, zeros, eye, evalf, ccode, Rational"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f388c0e0-3ac3-4f26-918f-ad1258b856df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle - \\frac{1}{2}$"
      ],
      "text/plain": [
       "-1/2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-Rational(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "457caba4-4829-427f-818b-e1e3fac69d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d23a31b-e8ce-47b5-848a-17084a7b35c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([0,1,2,3,4,5],dtype=np.float32).reshape(3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a33b7c4c-7ba5-41d3-93b2-8c05cb335159",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.array([0,1,2,3,4,5],dtype=np.float32).reshape(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fafa75d4-a5a8-4ba6-aecb-361272593490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.,  4.,  5.],\n",
       "       [ 9., 14., 19.],\n",
       "       [15., 24., 33.]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a@b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d404665-b523-4a74-92ab-15c034f1f2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "bb = np.transpose(b.reshape(3,2),[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "841fdd07-0f22-47bd-8ce6-daf0c70c23e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 2., 4.],\n",
       "       [1., 3., 5.]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e808bbd1-4dca-4a4d-9d20-5e974791bbf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 2.],\n",
       "       [3., 4., 5.]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0fdb2ac5-28f0-4fcb-80e1-406e60d9957f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  3.,  5.],\n",
       "       [ 3., 13., 23.],\n",
       "       [ 5., 23., 41.]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a @ bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6475d3-1381-47fa-97d1-14aba1ff6484",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
