{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout 丢弃法\n",
    "\n",
    "丢弃法不改变其输入的期望值，即$E(h'_i)=\\frac{E(\\xi_i)}{1-p} h_i = hi$，其中$p(\\xi_i=0)=p$，$p(\\xi_i=1)=1-p$。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io, os, sys, types\n",
    "from IPython import get_ipython\n",
    "from nbformat import read\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "def find_notebook(fullname, path=None):\n",
    "    \"\"\"find a notebook, given its fully qualified name and an optional path\n",
    "    \n",
    "    This turns \"foo.bar\" into \"foo/bar.ipynb\"\n",
    "    and tries turning \"Foo_Bar\" into \"Foo Bar\" if Foo_Bar\n",
    "    does not exist.\n",
    "    \"\"\"\n",
    "    name = fullname.rsplit('.', 1)[-1]\n",
    "    if not path:\n",
    "        path = ['']\n",
    "    for d in path:\n",
    "        nb_path = os.path.join(d, name + \".ipynb\")\n",
    "        if os.path.isfile(nb_path):\n",
    "            return nb_path\n",
    "        # let import Notebook_Name find \"Notebook Name.ipynb\"\n",
    "        nb_path = nb_path.replace(\"_\", \" \")\n",
    "        if os.path.isfile(nb_path):\n",
    "            return nb_path\n",
    "        \n",
    "class NotebookLoader(object):\n",
    "    \"\"\"Module Loader for Jupyter Notebooks\"\"\"\n",
    "    def __init__(self, path=None):\n",
    "        self.shell = InteractiveShell.instance()\n",
    "        self.path = path\n",
    "    \n",
    "    def load_module(self, fullname):\n",
    "        \"\"\"import a notebook as a module\"\"\"\n",
    "        path = find_notebook(fullname, self.path)\n",
    "        \n",
    "        print (\"importing Jupyter notebook from %s\" % path)\n",
    "                                       \n",
    "        # load the notebook object\n",
    "        with io.open(path, 'r', encoding='utf-8') as f:\n",
    "            nb = read(f, 4)\n",
    "        \n",
    "        \n",
    "        # create the module and add it to sys.modules\n",
    "        # if name in sys.modules:\n",
    "        #    return sys.modules[name]\n",
    "        mod = types.ModuleType(fullname)\n",
    "        mod.__file__ = path\n",
    "        mod.__loader__ = self\n",
    "        mod.__dict__['get_ipython'] = get_ipython\n",
    "        sys.modules[fullname] = mod\n",
    "        \n",
    "        # extra work to ensure that magics that would affect the user_ns\n",
    "        # actually affect the notebook module's ns\n",
    "        save_user_ns = self.shell.user_ns\n",
    "        self.shell.user_ns = mod.__dict__\n",
    "        \n",
    "        try:\n",
    "          for cell in nb.cells:\n",
    "            if cell.cell_type == 'code':\n",
    "                # transform the input to executable Python\n",
    "                code = self.shell.input_transformer_manager.transform_cell(cell.source)\n",
    "                # run the code in themodule\n",
    "                exec(code, mod.__dict__)\n",
    "        finally:\n",
    "            self.shell.user_ns = save_user_ns\n",
    "        return mod\n",
    "class NotebookFinder(object):\n",
    "    \"\"\"Module finder that locates Jupyter Notebooks\"\"\"\n",
    "    def __init__(self):\n",
    "        self.loaders = {}\n",
    "    \n",
    "    def find_module(self, fullname, path=None):\n",
    "        nb_path = find_notebook(fullname, path)\n",
    "        if not nb_path:\n",
    "            return\n",
    "        \n",
    "        key = path\n",
    "        if path:\n",
    "            # lists aren't hashable\n",
    "            key = os.path.sep.join(path)\n",
    "        \n",
    "        if key not in self.loaders:\n",
    "            self.loaders[key] = NotebookLoader(path)\n",
    "        return self.loaders[key]\n",
    "\n",
    "sys.meta_path.append(NotebookFinder())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_out(X,drop_prob):\n",
    "    X=X.float()\n",
    "    assert 0 <= drop_prob <= 1\n",
    "    keep_prob = 1-drop_prob\n",
    "    #此种情况全部舍弃此隐藏层全部单元\n",
    "    if keep_prob == 0:\n",
    "        return torch.zeros_like(X)\n",
    "    #此种情况，随机舍去概率小于keep_prob的单元\n",
    "    mask = (torch.rand(X.shape) < keep_prob).float()\n",
    "    \n",
    "    return mask*X / keep_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=torch.arange(16).view(2,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.],\n",
       "        [ 8.,  9., 10., 11., 12., 13., 14., 15.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_out(X,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  0.,  0.,  0.,  8., 10.,  0.,  0.],\n",
       "        [16., 18., 20.,  0., 24., 26., 28., 30.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_out(X,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs, num_outputs, num_hiddens1, num_hiddens2 = 784, 10, 256, 256\n",
    "#两个隐藏层，输出个数都为256\n",
    "W1 = torch.tensor(np.random.normal(0, 0.01, size=(num_inputs, num_hiddens1)), dtype=torch.float, requires_grad=True)\n",
    "b1 = torch.zeros(num_hiddens1, requires_grad=True)\n",
    "W2 = torch.tensor(np.random.normal(0, 0.01, size=(num_hiddens1, num_hiddens2)), dtype=torch.float, requires_grad=True)\n",
    "b2 = torch.zeros(num_hiddens2, requires_grad=True)\n",
    "W3 = torch.tensor(np.random.normal(0, 0.01, size=(num_hiddens2, num_outputs)), dtype=torch.float, requires_grad=True)\n",
    "b3 = torch.zeros(num_outputs, requires_grad=True)\n",
    "\n",
    "params = [W1, b1, W2, b2, W3, b3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_prob1,drop_prob2 = 0.2,0.5\n",
    "#由输入层起始的隐藏层丢弃概率应该小一点，后面的丢弃概率可以大一点\n",
    "def net(X,is_training=True):\n",
    "    X = X.view(-1,num_inputs)\n",
    "    H1 = (torch.matmul(X,W1)+b1).relu()\n",
    "    if is_training:\n",
    "        H1 = drop_out(H1,drop_prob1)\n",
    "    \n",
    "    H2=(torch.matmul(H1,W2)+b2).relu()\n",
    "    \n",
    "    if is_training:\n",
    "        H2 = drop_out(H2,drop_prob2)\n",
    "    return torch.matmul(H2,W3)+b3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iter,net):\n",
    "    #准确的样本数目\n",
    "    acc_sum = 0.0\n",
    "    #总样本数\n",
    "    n=0\n",
    "    #统计准确率的情况下不应该进行dropout\n",
    "    for X,y in data_iter:\n",
    "        #net 符合pytorch的Module\n",
    "        if isinstance(net,torch.nn.Module):\n",
    "            net.eval()#模型评估模式，关闭dropout\n",
    "            acc_sum+=(net(X).argmax(dim=1) == y).float().sum().item()\n",
    "            net.train()\n",
    "        else:\n",
    "            if('is_training' in net.__code__.co_varnames):\n",
    "                acc_sum+=(net(X,False).argmax(dim=1) == y).float().sum().item()\n",
    "            else:\n",
    "                acc_sum+=(net(X).argmax(dim=1)==y).float().sum().item() \n",
    "        n+=y.shape[0]#y.shape[0]为batch_size个label\n",
    "    return acc_sum /n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ch3(net,train_iter,test_iter,loss,epochs,batch_size,params=None,lr=None,optimizer=None):\n",
    "    #训练\n",
    "    for epoch in range(epochs):\n",
    "        train_l_sum , train_acc_sum,n= 0.0,0.0,0\n",
    "        for X,y in train_iter:#X为图像\n",
    "            y_hat=net(X)#对该次输入的预测值\n",
    "            l = loss(y_hat,y).sum()\n",
    "            \n",
    "            #梯度清零\n",
    "            if optimizer is not None:\n",
    "                optimizer.zero_grad()\n",
    "            elif params is not None and params[0].grad is not None:\n",
    "                for param in params:\n",
    "                    param.grad.data.zero_()\n",
    "            \n",
    "            l.backward()\n",
    "            \n",
    "            if optimizer is None:\n",
    "                d2l.sgd(params,lr,batch_size)\n",
    "            else:\n",
    "                optimizer.step()\n",
    "                \n",
    "            \n",
    "            train_l_sum += l.item()#统计总的损失\n",
    "            train_acc_sum+=(y_hat.argmax(dim=1) == y).sum().item()#统计准确率\n",
    "            #y.shape[0]为batch_size个label\n",
    "            n+=y.shape[0]\n",
    "        #一个epoch走完\n",
    "        test_acc = evaluate_accuracy(test_iter,net)\n",
    "        print(\"Epoch %d, loss %.4f, train accuracy %.3f, test accuracy %.3f\" %(epoch+1,train_l_sum/n,train_acc_sum/n,test_acc))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss 0.0045, train accuracy 0.557, test accuracy 0.752\n",
      "Epoch 2, loss 0.0023, train accuracy 0.786, test accuracy 0.825\n",
      "Epoch 3, loss 0.0019, train accuracy 0.821, test accuracy 0.820\n",
      "Epoch 4, loss 0.0017, train accuracy 0.838, test accuracy 0.790\n",
      "Epoch 5, loss 0.0016, train accuracy 0.849, test accuracy 0.847\n"
     ]
    }
   ],
   "source": [
    "num_epochs, lr, batch_size = 5, 100.0, 256#学习率设置的大一点（因为是自己实现的SGD）\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "train_iter, test_iter = d2l.load_data_from_fmnist(batch_size)\n",
    "train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size, params, lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 简洁实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "        d2l.FlattenLayer(),#自定义形变层\n",
    "        nn.Linear(num_inputs,num_hiddens1),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(drop_prob1),\n",
    "        nn.Linear(num_hiddens1,num_hiddens2),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(drop_prob2),\n",
    "        nn.Linear(num_hiddens2,10)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in net.parameters():\n",
    "    nn.init.normal_(param,mean=0,std=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss 0.0046, train accuracy 0.546, test accuracy 0.741\n",
      "Epoch 2, loss 0.0023, train accuracy 0.787, test accuracy 0.744\n",
      "Epoch 3, loss 0.0019, train accuracy 0.823, test accuracy 0.809\n",
      "Epoch 4, loss 0.0017, train accuracy 0.837, test accuracy 0.837\n",
      "Epoch 5, loss 0.0016, train accuracy 0.847, test accuracy 0.845\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(net.parameters(),lr=0.5)\n",
    "train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size,None,None,optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
